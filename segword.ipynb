{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import InceptionV3,preprocess_input\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.optimizers import Adagrad,Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import keras\n",
    "# 数据准备\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,# ((x/255)-0.5)*2  归一化到±1之间\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    ")\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里用到的数据集和之前都不同，之前用的是一些公共的、Keras内置的数据集，这次用到的是自己准备的数据集。由于数据的图像大小比较大，不适合一次全部载入到内存中，所以使用了flow_from_directory方法来按批次从硬盘读取图像数据，并实时进行图像增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory='./chnData/train',\n",
    "                                  target_size=(32,32),#Inception V3规定大小\n",
    "                                  batch_size=64)\n",
    "val_generator = val_datagen.flow_from_directory(directory='./chnData/test',\n",
    "                                target_size=(32,32),\n",
    "                                batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们需要加载骨架模型，这里用的InceptionV3模型，其两个参数比较重要，一个是weights，如果是'imagenet',Keras就会自动下载已经在ImageNet上训练好的参数，如果是None，系统会通过随机的方式初始化参数，目前该参数只有这两个选择。另一个参数是include_top，如果是True，输出是1000个节点的全连接层。如果是False，会去掉顶层，输出一个8 \\* 8 \\* 2048的张量。 \n",
    "\n",
    "ps：在keras.applications里还有很多其他的预置模型，比如VGG，ResNet，以及适用于移动端的MobileNet等。大家都可以拿来玩玩。\n",
    "\n",
    "一般我们做迁移训练，都是要去掉顶层，后面接上各种自定义的其它新层。这已经成为了训练新任务惯用的套路。\n",
    "输出层先用GlobalAveragePooling2D函数将8 \\* 8 \\* 2048的输出转换成1 \\* 2048的张量。后面接了一个1024个节点的全连接层，最后是一个17个节点的输出层，用softmax激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ResNet Block\n",
    "def resnet_block(inputs,num_filters=16,\n",
    "                  kernel_size=3,strides=1,\n",
    "                  activation='relu'):\n",
    "    x = Conv2D(num_filters,kernel_size=kernel_size,strides=strides,padding='same',\n",
    "           kernel_initializer='he_normal',kernel_regularizer=l2(1e-4))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    if(activation):\n",
    "        x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 建一个20层的ResNet网络 \n",
    "def resnet_v1(input_shape):\n",
    "    inputs = Input(shape=input_shape)# Input层，用来当做占位使用\n",
    "    \n",
    "    #第一层\n",
    "    x = resnet_block(inputs)\n",
    "    print('layer1,xshape:',x.shape)\n",
    "    # 第2~7层\n",
    "    for i in range(6):\n",
    "        a = resnet_block(inputs = x)\n",
    "        b = resnet_block(inputs=a,activation=None)\n",
    "        x = keras.layers.add([x,b])\n",
    "        x = Activation('relu')(x)\n",
    "    # out：32*32*16\n",
    "    # 第8~13层\n",
    "    for i in range(6):\n",
    "        if i == 0:\n",
    "            a = resnet_block(inputs = x,strides=2,num_filters=32)\n",
    "        else:\n",
    "            a = resnet_block(inputs = x,num_filters=32)\n",
    "        b = resnet_block(inputs=a,activation=None,num_filters=32)\n",
    "        if i==0:\n",
    "            x = Conv2D(32,kernel_size=3,strides=2,padding='same',\n",
    "                       kernel_initializer='he_normal',kernel_regularizer=l2(1e-4))(x)\n",
    "        x = keras.layers.add([x,b])\n",
    "        x = Activation('relu')(x)\n",
    "    # out:16*16*32\n",
    "    # 第14~19层\n",
    "    for i in range(6):\n",
    "        if i ==0 :\n",
    "            a = resnet_block(inputs = x,strides=2,num_filters=64)\n",
    "        else:\n",
    "            a = resnet_block(inputs = x,num_filters=64)\n",
    "\n",
    "        b = resnet_block(inputs=a,activation=None,num_filters=64)\n",
    "        if i == 0:\n",
    "            x = Conv2D(64,kernel_size=3,strides=2,padding='same',\n",
    "                       kernel_initializer='he_normal',kernel_regularizer=l2(1e-4))(x)\n",
    "        x = keras.layers.add([x,b])# 相加操作，要求x、b shape完全一致\n",
    "        x = Activation('relu')(x)\n",
    "    # out:8*8*64\n",
    "    # 第20层   \n",
    "    x = AveragePooling2D(pool_size=2)(x)\n",
    "    # out:4*4*64\n",
    "    y = Flatten()(x)\n",
    "    # out:1024\n",
    "    outputs = Dense(3562,activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "    \n",
    "    #初始化模型\n",
    "    #之前的操作只是将多个神经网络层进行了相连，通过下面这一句的初始化操作，才算真正完成了一个模型的结构初始化\n",
    "    model = Model(inputs=inputs,outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_v1((32,32,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./logs',  # log 目录\n",
    "                 histogram_freq=0,  # 按照何等频率（epoch）来计算直方图，0为不计算\n",
    "                 batch_size=32,     # 用多大量的数据计算直方图\n",
    "                 write_graph=False,  # 是否存储网络结构图\n",
    "                 write_grads=False, # 是否可视化梯度直方图\n",
    "                 write_images=False,# 是否可视化参数\n",
    "                 embeddings_freq=0, \n",
    "                 embeddings_layer_names=None, \n",
    "                 embeddings_metadata=None)\n",
    "checkpoint = ModelCheckpoint(filepath='./chnData_resnet_ckpt.h5',monitor='val_acc',\n",
    "                             verbose=1,save_best_only=True)\n",
    "callbacks = [tb,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_tl = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=800,#800\n",
    "                    epochs=20,#2\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=12,#12\n",
    "                    class_weight='auto',\n",
    "                    callbacks=callbacks\n",
    "                    )\n",
    "model.save('./chnData_resnet.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
